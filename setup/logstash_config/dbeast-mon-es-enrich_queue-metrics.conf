input{
  http_poller {
    id => "Input-cat-indices-from-mon-ES" 
    urls => {
      lab => "/_enrich/_stats"
    }
    request_timeout => 60
    schedule => { "cron" => "* * * * *"}
    codec => "json"

	ssl_verification_mode => "none"
    add_field => {
	  "[elasticsearch][cluster][id]" => ""
	  "[event][dataset]" => "elasticsearch"
	  "[metricset][name]" => "enrich_queue_stats"
	}	
  }
}
filter{
  mutate {
    remove_field => ["[event][original]", "executing_policies"]
	rename => {
      "coordinator_stats" => "[elasticsearch][node][stats][ingest][enrich][coordinator_stats]"
      "cache_stats" => "[elasticsearch][node][stats][ingest][enrich][cache_stats]"
    }
  }
  split {
    field => "[elasticsearch][node][stats][ingest][enrich][coordinator_stats]"
  } 
  split {
    field => "[elasticsearch][node][stats][ingest][enrich][cache_stats]"
  } 
  
  if !([elasticsearch][node][stats][ingest][enrich][cache_stats][node_id] in [elasticsearch][node][stats][ingest][enrich][coordinator_stats][node_id]){
    drop {}
  }

	aggregate {
     task_id => "%{[elasticsearch][cluster][id]}%{[elasticsearch][node][stats][ingest][enrich][coordinator_stats][node_id]}"
     code => "
	    require 'date';
		#Date in seconds
		sample_date = Time.now.to_i;
		event.set('sample_date', sample_date);
    
	 	#Calculate rates 
	 	if 	map.key?('last_sample_date')
	 	  date_diff = ( sample_date - map['last_sample_date'] );

		  #Calculate rates for processor
		  if event.get('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_total]') > 0
		    event.set('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_last_period]', (event.get('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_total]') - map['last_executed_searches_total']));
			event.set('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_rate]', (event.get('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_last_period]')/date_diff).ceil);	
			event.set('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits_last_period]', (event.get('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits]') - map['last_hits']));
			event.set('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits_rate]', (event.get('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits_last_period]')/date_diff).ceil);
		  else
		    event.set('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_last_period]', 0);
		    event.set('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_rate]', 0);
		    event.set('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits_last_period]', 0);
		    event.set('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits_rate]', 0);
		  end
		  map['first_doc'] = false;
	 	else
	 	  map['first_doc'] = true;
		end 
		
		map['last_executed_searches_total'] = event.get('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_total]').to_i;
		map['last_hits'] = event.get('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits]').to_i;

	 	map['last_sample_date'] =  sample_date;	  		
	    #Drop document if there is no preview documents.
	 	if map['first_doc']
	 	  event.cancel();
	 	end
     "
     timeout => 3000000
     push_map_as_event_on_timeout => false
   
 }	
  mutate {
    rename => {
	  "[elasticsearch][node][stats][ingest][enrich][coordinator_stats][node_id]" => "[elasticsearch][node][id]"
    }
	remove_field => ["monitoring", "events", "[elasticsearch][node][stats][ingest][enrich][cache_stats][node_id]"]

  }
}
output{
  elasticsearch {

      index => "mon-es-ingest_pipelienes-%{+YYYY.MM.dd}"   
	  manage_template => false
  }
  elasticsearch {
    
      index => "mon-es-ingest_pipelienes-status"   
	  manage_template => false
	  document_id => "%{[elasticsearch][cluster][id]}-%{[elasticsearch][node][id]}"
  }

#  stdout{
#   codec => rubydebug
#  }
}
